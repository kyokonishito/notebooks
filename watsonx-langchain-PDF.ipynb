{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# watsonx.aiのLLMでLangChainを使ってPDFの内容をQ&Aをする\n",
    "\n",
    "https://qiita.com/nishikyon/items/5054209089fc632981f8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 必要なライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ibm-watson-machine-learning\n",
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install chromadb\n",
    "!pip install unstructured\n",
    "!pip install sentence_transformers\n",
    "!pip install flask-sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**インストール終了後、一旦カーネルを再起動してください**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (オプション)LangChainで使えるLLMの確認\n",
    "`LLAMA_2_70B_CHAT`が表示されたか確認してください。\n",
    "表示されていない場合は`ibm-watson-machine-learning`のバージョンが古いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "print([model.name for model in ModelTypes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChainで使えるLLMの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\", # watsonx.aiのAuthentication用のエンドポイントのURL\n",
    "    \"apikey\": \"<APIキー>\"\n",
    "}\n",
    "project_id = \"<PROJECT ID>\"\n",
    "\n",
    "# 使用するLLMのパラメータ\n",
    "generate_params = {\n",
    "    GenParams.MAX_NEW_TOKENS: 500,\n",
    "    GenParams.MIN_NEW_TOKENS: 0,\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.REPETITION_PENALTY: 1\n",
    "}\n",
    "\n",
    "# モデルの初期化\n",
    "model = Model(\n",
    "    model_id=ModelTypes.LLAMA_2_70B_CHAT, #使用するLLM名\n",
    "    credentials=credentials,\n",
    "    params=generate_params,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "# LangChainで使うllm\n",
    "custom_llm = WatsonxLLM(model=model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# そのまま実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=custom_llm(\"IBM Db2 on Cloudの特徴は?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://files.speakerdeck.com/presentations/cc34f85fe9b5467d8782a41e5fa39b78/Dojo_Db2RESTAPI_20230727_%E9%85%8D%E5%B8%83%E7%94%A8.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./Dojo_Db2RESTAPI_20230727_配布用.pdf\") #ダウンロードしたPDFを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexの作成\n",
    "\n",
    "`ImportError: cannot import name 'URL' from 'sqlalchemy'`というエラーがでたら、一旦カーネルをリスタートして、やり直してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings()).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロプントを考えずに聞いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"IBM TechXchange Japanとは。\"\n",
    "answer = index.query(llm=custom_llm, question=query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試しに絶対にPDFにない簡単な質問をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"日本の首都は?\"\n",
    "answer = index.query(llm=custom_llm, question=query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieverの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={'score_threshold': 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロンプトの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"[INST] <<SYS>>Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "<</SYS>>\n",
    "Question: {question}\n",
    "Answer in Japanese:[/INST]\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrievalQAの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=custom_llm, chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs=chain_type_kwargs, \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質問してみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"IBM TechXchange Japanとは?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n",
    "print(\"-------------------\")\n",
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"日本の首都は?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n",
    "print(\"-------------------\")\n",
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Db2 on Cloud REST APIを使うには、まず何をしますか?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n",
    "print(\"-------------------\")\n",
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=custom_llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "query = \"Db2 on Cloud REST APIを使うには、まず何をしますか?\" \n",
    "answer = qa.run(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
